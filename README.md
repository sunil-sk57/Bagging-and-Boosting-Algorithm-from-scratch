# Bagging-and-Boosting-Algorithm-from-scratch
Implementing logistic regression and getting the best kernel and regularisation parameters for linear, RBF and Poly kernels. 

Implementing Decision tree from scratch with hyperparameter tuning. 

Implementing Random Forest(Bagging Model) using decision tree implemented above with hyperparameter tuning. 

Implementing Adaboost(Boosting model) using 3 different weak learners below. 

1 node decision tree 

Decision tree of fixed depth = 3 (Root, child, grand child) 

Decision tree of fixed depth = 7 (Root, child, grand child, ..., great^4 grand child)
